{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663cd58c-fa9e-4a6b-9955-9bac98d93451",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-11T04:01:54.551797Z",
     "iopub.status.busy": "2024-12-11T04:01:54.551533Z",
     "iopub.status.idle": "2024-12-11T04:02:29.001556Z",
     "shell.execute_reply": "2024-12-11T04:02:29.000980Z",
     "shell.execute_reply.started": "2024-12-11T04:01:54.551773Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:01:59.698100: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 12:01:59.738486: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 12:02:00.447967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:02,538 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect\n",
      "2024-12-11 12:02:02,539 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect.\n",
      "2024-12-11 12:02:02,542 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect\n",
      "/usr/local/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/albumentations/check_version.py:51: UserWarning: Error fetching version info The read operation timed out\n",
      "  data = fetch_version_info()\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "2024-12-11 12:02:16,524 - mmcv - INFO - initialize PAFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2024-12-11 12:02:16,526 - mmcv - INFO - \n",
      "lateral_convs.0.conv.weight - torch.Size([16, 64, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,526 - mmcv - INFO - \n",
      "lateral_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,526 - mmcv - INFO - \n",
      "lateral_convs.1.conv.weight - torch.Size([16, 120, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,527 - mmcv - INFO - \n",
      "lateral_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,527 - mmcv - INFO - \n",
      "lateral_convs.2.conv.weight - torch.Size([16, 160, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,527 - mmcv - INFO - \n",
      "lateral_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,528 - mmcv - INFO - \n",
      "fpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,528 - mmcv - INFO - \n",
      "fpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,528 - mmcv - INFO - \n",
      "fpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,529 - mmcv - INFO - \n",
      "fpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,529 - mmcv - INFO - \n",
      "fpn_convs.2.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,529 - mmcv - INFO - \n",
      "fpn_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,529 - mmcv - INFO - \n",
      "downsample_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,530 - mmcv - INFO - \n",
      "downsample_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,530 - mmcv - INFO - \n",
      "downsample_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,530 - mmcv - INFO - \n",
      "downsample_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,531 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,531 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,531 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:16,532 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:16,534 - modelscope - INFO - loading model from /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect/pytorch_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect/pytorch_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:17,998 - modelscope - INFO - load model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:18,741 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2024-12-11 12:02:19,058 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint\n",
      "2024-12-11 12:02:19,059 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint.\n",
      "2024-12-11 12:02:19,068 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-12-11 12:02:19,068 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-12-11 12:02:19,068 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint'}. trying to build by task and model information.\n",
      "2024-12-11 12:02:19,069 - modelscope - WARNING - Find task: face-recognition, model type: None. Insufficient information to build preprocessor, skip building preprocessor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:19,667 - modelscope - WARNING - Model revision not specified, use revision: v1.1\n",
      "2024-12-11 12:02:20,062 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n",
      "2024-12-11 12:02:20,062 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd.\n",
      "2024-12-11 12:02:20,066 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "2024-12-11 12:02:20,103 - mmcv - INFO - initialize PAFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2024-12-11 12:02:20,105 - mmcv - INFO - \n",
      "lateral_convs.0.conv.weight - torch.Size([16, 64, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,106 - mmcv - INFO - \n",
      "lateral_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,106 - mmcv - INFO - \n",
      "lateral_convs.1.conv.weight - torch.Size([16, 120, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,106 - mmcv - INFO - \n",
      "lateral_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,107 - mmcv - INFO - \n",
      "lateral_convs.2.conv.weight - torch.Size([16, 160, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,108 - mmcv - INFO - \n",
      "lateral_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,108 - mmcv - INFO - \n",
      "fpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,109 - mmcv - INFO - \n",
      "fpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,109 - mmcv - INFO - \n",
      "fpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,109 - mmcv - INFO - \n",
      "fpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,110 - mmcv - INFO - \n",
      "fpn_convs.2.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,110 - mmcv - INFO - \n",
      "fpn_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,111 - mmcv - INFO - \n",
      "downsample_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,111 - mmcv - INFO - \n",
      "downsample_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,112 - mmcv - INFO - \n",
      "downsample_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,112 - mmcv - INFO - \n",
      "downsample_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,112 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,113 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,113 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:20,114 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:20,116 - modelscope - INFO - loading model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt\n",
      "2024-12-11 12:02:20,159 - modelscope - INFO - load model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:21,627 - modelscope - INFO - face recognition model loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/damo/cv_vgg19_facial-expression-recognition_fer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:22,405 - modelscope - WARNING - Model revision not specified, use revision: v2.0.2\n",
      "2024-12-11 12:02:22,726 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/damo/cv_vgg19_facial-expression-recognition_fer\n",
      "2024-12-11 12:02:22,727 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/damo/cv_vgg19_facial-expression-recognition_fer.\n",
      "2024-12-11 12:02:22,735 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-12-11 12:02:22,736 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-12-11 12:02:22,736 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/hub/damo/cv_vgg19_facial-expression-recognition_fer'}. trying to build by task and model information.\n",
      "2024-12-11 12:02:22,736 - modelscope - WARNING - Find task: facial-expression-recognition, model type: None. Insufficient information to build preprocessor, skip building preprocessor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:23,387 - modelscope - WARNING - Model revision not specified, use revision: v1.1\n",
      "2024-12-11 12:02:23,774 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n",
      "2024-12-11 12:02:23,775 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd.\n",
      "2024-12-11 12:02:23,778 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n",
      "2024-12-11 12:02:23,811 - mmcv - INFO - initialize PAFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2024-12-11 12:02:23,812 - mmcv - INFO - \n",
      "lateral_convs.0.conv.weight - torch.Size([16, 64, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,813 - mmcv - INFO - \n",
      "lateral_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,813 - mmcv - INFO - \n",
      "lateral_convs.1.conv.weight - torch.Size([16, 120, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,813 - mmcv - INFO - \n",
      "lateral_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,814 - mmcv - INFO - \n",
      "lateral_convs.2.conv.weight - torch.Size([16, 160, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,814 - mmcv - INFO - \n",
      "lateral_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,814 - mmcv - INFO - \n",
      "fpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,815 - mmcv - INFO - \n",
      "fpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,815 - mmcv - INFO - \n",
      "fpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,815 - mmcv - INFO - \n",
      "fpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,815 - mmcv - INFO - \n",
      "fpn_convs.2.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,816 - mmcv - INFO - \n",
      "fpn_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,816 - mmcv - INFO - \n",
      "downsample_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,816 - mmcv - INFO - \n",
      "downsample_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,817 - mmcv - INFO - \n",
      "downsample_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,817 - mmcv - INFO - \n",
      "downsample_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,817 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,817 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,818 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-11 12:02:23,818 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-11 12:02:23,820 - modelscope - INFO - loading model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt\n",
      "2024-12-11 12:02:23,851 - modelscope - INFO - load model done\n",
      "2024-12-11 12:02:23,865 - modelscope - INFO - loading model from /mnt/workspace/.cache/modelscope/hub/damo/cv_vgg19_facial-expression-recognition_fer/pytorch_model.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:24,180 - modelscope - INFO - load model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/damo/cv_unet_image-matting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:24,902 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2024-12-11 12:02:25,200 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/damo/cv_unet_image-matting\n",
      "2024-12-11 12:02:25,200 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/damo/cv_unet_image-matting.\n",
      "2024-12-11 12:02:25,209 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-12-11 12:02:25,210 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-12-11 12:02:25,210 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/hub/damo/cv_unet_image-matting'}. trying to build by task and model information.\n",
      "2024-12-11 12:02:25,210 - modelscope - WARNING - Find task: portrait-matting, model type: None. Insufficient information to build preprocessor, skip building preprocessor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/site-packages/modelscope/utils/device.py:60: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:25.215212: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.229028: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.229222: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.229393: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.229504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.229602: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.229716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /device:GPU:0 with 19817 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:00:07.0, compute capability: 8.6\n",
      "2024-12-11 12:02:25.230673: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.230825: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.230940: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.231275: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.231382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.231467: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.231580: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.231670: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.231748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19817 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:00:07.0, compute capability: 8.6\n",
      "2024-12-11 12:02:25.232645: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.232772: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.232902: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.233041: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.233168: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:02:25.233267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 19817 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:00:07.0, compute capability: 8.6\n",
      "2024-12-11 12:02:25,233 - modelscope - INFO - loading model from /mnt/workspace/.cache/modelscope/hub/damo/cv_unet_image-matting/tf_graph.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.10/site-packages/modelscope/pipelines/cv/image_matting_pipeline.py:45: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 12:02:25,681 - modelscope - INFO - load model done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://0fc5d4e228389b9d4d.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0fc5d4e228389b9d4d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:333: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:369: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:333: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:369: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/modelscope/models/cv/facial_expression_recognition/fer/transforms.py:19: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  img = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))\n",
      "/usr/local/lib/python3.10/site-packages/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py:63: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs = Variable(inputs, volatile=True)\n",
      "/usr/local/lib/python3.10/site-packages/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score = F.softmax(outputs_avg)\n",
      "2024-12-11 12:06:28,522 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:28,538 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:28,606 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:28,640 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:28,709 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:28,814 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:28,848 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:28,935 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:28,967 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:28,981 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:28,997 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:29,084 - modelscope - INFO - Warning: No face detected!\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:333: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:369: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:333: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:369: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py:63: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  inputs = Variable(inputs, volatile=True)\n",
      "/usr/local/lib/python3.10/site-packages/modelscope/models/cv/facial_expression_recognition/fer/facial_expression_recognition.py:68: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  score = F.softmax(outputs_avg)\n",
      "2024-12-11 12:06:59,215 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:59,235 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:59,322 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:59,358 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:59,425 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:59,539 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:59,578 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:59,673 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:59,705 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:59,719 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:06:59,734 - modelscope - INFO - Warning: Face size not enough, less than 10x10!\n",
      "2024-12-11 12:06:59,817 - modelscope - INFO - Warning: No face detected!\n",
      "2024-12-11 12:07:35.377502: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:07:35.377715: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:07:35.377831: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:07:35.377984: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:07:35.378073: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 12:07:35.378153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /device:GPU:0 with 19817 MB memory:  -> device: 0, name: NVIDIA A10, pci bus id: 0000:00:07.0, compute capability: 8.6\n",
      "2024-12-11 12:07:35.484153: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-12-11 12:07:36.836490: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8902\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from modelscope.outputs import OutputKeys\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "from util import *\n",
    "import cv2\n",
    "\n",
    "face_detector = pipeline(Tasks.face_detection, model='gaosheng/face_detect')\n",
    "# face_recognizer = pipeline(Tasks.face_recognition, model='damo/cv_ir101_facerecognition_cfglint')\n",
    "face_recognizer = pipeline(Tasks.face_recognition, model='iic/cv_ir101_facerecognition_cfglint')\n",
    "emotion_recognizer = pipeline(Tasks.facial_expression_recognition, 'damo/cv_vgg19_facial-expression-recognition_fer')\n",
    "portrait_matting = pipeline(Tasks.portrait_matting, model='damo/cv_unet_image-matting')\n",
    "face_bank = load_face_bank('face_bank/', face_recognizer)\n",
    "name_box_map = {}\n",
    "detected_image = None\n",
    "original_image = None\n",
    "\n",
    "\n",
    "def inference(img: Image, draw_detect_enabled, detect_threshold, sim_threshold) -> json:\n",
    "    global original_image\n",
    "    original_image = copy.deepcopy(img)\n",
    "\n",
    "    img = resize_img(img)\n",
    "    img = img.convert('RGB')\n",
    "\n",
    "    global detected_image\n",
    "    detected_image = copy.deepcopy(img)\n",
    "\n",
    "    detection_result = face_detector(img)\n",
    "    boxes = np.array(detection_result[OutputKeys.BOXES])\n",
    "    scores = np.array(detection_result[OutputKeys.SCORES])\n",
    "    faces = []\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        score = scores[i]\n",
    "        if score < detect_threshold:\n",
    "            continue\n",
    "        box = boxes[i]\n",
    "        face_embedding = get_face_embedding(img, box, face_recognizer)\n",
    "        name, sim = get_name_sim(face_embedding, face_bank)\n",
    "        if name is None:\n",
    "            continue\n",
    "        if sim < sim_threshold:\n",
    "            faces.append({'box': box, 'name': '未知', 'sim': sim})\n",
    "        else:\n",
    "            faces.append({'box': box, 'name': name, 'sim': sim})\n",
    "            real_name = name[2:] # 去掉前2位学号\n",
    "            name_box_map[real_name] = box\n",
    "    rows = get_rows(faces)\n",
    "    row_names = get_row_names(faces, rows)\n",
    "    draw_name(img, row_names)\n",
    "    if draw_detect_enabled:\n",
    "        draw_faces(img, faces, emotion_recognizer)\n",
    "    return img, get_row_names_text(row_names)\n",
    "\n",
    "def search_face_cutouts(name_input, audio_input):\n",
    "\n",
    "    name = name_input if name_input else speech_to_text(audio_input)\n",
    "\n",
    "    if name not in name_box_map:\n",
    "        return \"404.jpg\"\n",
    "\n",
    "    # 适当扩大边框范围，保证覆盖人脸但是又不会显得边框过大\n",
    "    box = name_box_map[name]\n",
    "    box[0] = box[0] - 5\n",
    "    box[2] = box[2] + 2\n",
    "    box[1] = box[1] - 2\n",
    "    box[3] = box[3] + 2\n",
    "\n",
    "    global original_image\n",
    "    original_image = original_image.convert('RGB')\n",
    "    original_image_box = []\n",
    "    original_image_box.append(original_image.width*(box[0]/detected_image.width))\n",
    "    original_image_box.append(original_image.height*(box[1]/detected_image.height))\n",
    "    original_image_box.append(original_image.width*(box[2]/detected_image.width))\n",
    "    original_image_box.append(original_image.height*(box[3]/detected_image.height))\n",
    "\n",
    "    face_img = get_face_img(original_image, original_image_box)\n",
    "    result = portrait_matting(face_img)\n",
    "    face_cutouts = result[OutputKeys.OUTPUT_IMG]\n",
    "    # 要先写成本地图片才能保存颜色(原始的npy array会导致丢部分颜色信息)\n",
    "    cv2.imwrite('temp.png', face_cutouts)\n",
    "    # 抠图之后的图像太小，需要等比放大一些\n",
    "    # face_cutouts = Image.open('temp.png')\n",
    "    # original_width, original_height = face_cutouts.size\n",
    "    # new_width = original_width * 5\n",
    "    # new_height = original_height * 5\n",
    "    # resized_face_cutouts = face_cutouts.resize((new_width, new_height), Image.LANCZOS)\n",
    "    return 'temp.png'\n",
    "\n",
    "examples = ['example.jpg']\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        draw_detect_enabled = gr.Checkbox(label=\"是否画框\", value=True)\n",
    "        detect_threshold = gr.Slider(label=\"检测阈值\", minimum=0, maximum=1, value=0.3)\n",
    "        sim_threshold = gr.Slider(label=\"识别阈值\", minimum=0, maximum=1, value=0.3)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            img_input = gr.Image(type=\"pil\", height=350)\n",
    "            submit = gr.Button(\"提交\")\n",
    "        with gr.Column():\n",
    "            img_output = gr.Image(type=\"pil\")\n",
    "            name_output = gr.Text(label=\"人名\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            name_input = gr.Text(label=\"输入人名搜索头像\")\n",
    "            audio_input = gr.Audio(sources=[\"microphone\"], type=\"filepath\") \n",
    "            submit2 = gr.Button(\"提交\")\n",
    "        with gr.Column():\n",
    "            face_cutouts = gr.Image(type=\"pil\")\n",
    "    submit.click(\n",
    "        fn=inference,\n",
    "        inputs=[img_input, draw_detect_enabled, detect_threshold, sim_threshold],\n",
    "        outputs=[img_output, name_output])\n",
    "    submit2.click(\n",
    "        fn=search_face_cutouts,\n",
    "        inputs=[name_input, audio_input],\n",
    "        outputs=[face_cutouts])\n",
    "    gr.Examples(examples, inputs=[img_input])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
