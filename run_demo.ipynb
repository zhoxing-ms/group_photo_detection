{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663cd58c-fa9e-4a6b-9955-9bac98d93451",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2024-12-07T23:54:26.190777Z",
     "iopub.status.busy": "2024-12-07T23:54:26.190446Z",
     "iopub.status.idle": "2024-12-07T23:54:43.280183Z",
     "shell.execute_reply": "2024-12-07T23:54:43.279708Z",
     "shell.execute_reply.started": "2024-12-07T23:54:26.190756Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 07:54:32,397 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect\n",
      "2024-12-08 07:54:32,398 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect.\n",
      "2024-12-08 07:54:32,402 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect\n",
      "/usr/local/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 1.4.21). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "2024-12-08 07:54:36,124 - mmcv - INFO - initialize PAFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2024-12-08 07:54:36,126 - mmcv - INFO - \n",
      "lateral_convs.0.conv.weight - torch.Size([16, 64, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,126 - mmcv - INFO - \n",
      "lateral_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,127 - mmcv - INFO - \n",
      "lateral_convs.1.conv.weight - torch.Size([16, 120, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,127 - mmcv - INFO - \n",
      "lateral_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,127 - mmcv - INFO - \n",
      "lateral_convs.2.conv.weight - torch.Size([16, 160, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,127 - mmcv - INFO - \n",
      "lateral_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,128 - mmcv - INFO - \n",
      "fpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,128 - mmcv - INFO - \n",
      "fpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,128 - mmcv - INFO - \n",
      "fpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,128 - mmcv - INFO - \n",
      "fpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,129 - mmcv - INFO - \n",
      "fpn_convs.2.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,129 - mmcv - INFO - \n",
      "fpn_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,129 - mmcv - INFO - \n",
      "downsample_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,129 - mmcv - INFO - \n",
      "downsample_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,130 - mmcv - INFO - \n",
      "downsample_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,130 - mmcv - INFO - \n",
      "downsample_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,130 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,131 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,131 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:36,131 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:36,133 - modelscope - INFO - loading model from /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect/pytorch_model.pt\n",
      "2024-12-08 07:54:36,165 - modelscope - INFO - load model done\n",
      "2024-12-08 07:54:36,177 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /mnt/workspace/.cache/modelscope/hub/gaosheng/face_detect/pytorch_model.pt\n",
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 07:54:36,831 - modelscope - WARNING - Model revision not specified, use revision: v1.0.0\n",
      "2024-12-08 07:54:37,143 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint\n",
      "2024-12-08 07:54:37,143 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint.\n",
      "2024-12-08 07:54:37,156 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2024-12-08 07:54:37,156 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-12-08 07:54:37,156 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/hub/iic/cv_ir101_facerecognition_cfglint'}. trying to build by task and model information.\n",
      "2024-12-08 07:54:37,157 - modelscope - WARNING - Find task: face-recognition, model type: None. Insufficient information to build preprocessor, skip building preprocessor\n",
      "2024-12-08 07:54:37,161 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 07:54:37,944 - modelscope - WARNING - Model revision not specified, use revision: v1.1\n",
      "2024-12-08 07:54:38,285 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n",
      "2024-12-08 07:54:38,286 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd.\n",
      "2024-12-08 07:54:38,290 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "2024-12-08 07:54:38,323 - mmcv - INFO - initialize PAFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "2024-12-08 07:54:38,324 - mmcv - INFO - \n",
      "lateral_convs.0.conv.weight - torch.Size([16, 64, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,324 - mmcv - INFO - \n",
      "lateral_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,325 - mmcv - INFO - \n",
      "lateral_convs.1.conv.weight - torch.Size([16, 120, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,325 - mmcv - INFO - \n",
      "lateral_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,325 - mmcv - INFO - \n",
      "lateral_convs.2.conv.weight - torch.Size([16, 160, 1, 1]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,325 - mmcv - INFO - \n",
      "lateral_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,326 - mmcv - INFO - \n",
      "fpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,326 - mmcv - INFO - \n",
      "fpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,326 - mmcv - INFO - \n",
      "fpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,326 - mmcv - INFO - \n",
      "fpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,327 - mmcv - INFO - \n",
      "fpn_convs.2.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,327 - mmcv - INFO - \n",
      "fpn_convs.2.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,327 - mmcv - INFO - \n",
      "downsample_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,327 - mmcv - INFO - \n",
      "downsample_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,328 - mmcv - INFO - \n",
      "downsample_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,328 - mmcv - INFO - \n",
      "downsample_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,328 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,328 - mmcv - INFO - \n",
      "pafpn_convs.0.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,329 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.weight - torch.Size([16, 16, 3, 3]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "2024-12-08 07:54:38,329 - mmcv - INFO - \n",
      "pafpn_convs.1.conv.bias - torch.Size([16]): \n",
      "The value is the same before and after calling `init_weights` of PAFPN  \n",
      " \n",
      "2024-12-08 07:54:38,331 - modelscope - INFO - loading model from /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt\n",
      "2024-12-08 07:54:38,357 - modelscope - INFO - load model done\n",
      "2024-12-08 07:54:38,368 - modelscope - INFO - cuda is not available, using cpu instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: /mnt/workspace/.cache/modelscope/hub/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 07:54:39,703 - modelscope - INFO - face recognition model loaded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://ad30ca5c15b7bd78b2.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://ad30ca5c15b7bd78b2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from modelscope.outputs import OutputKeys\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from util import *\n",
    "\n",
    "face_detector = pipeline(Tasks.face_detection, model='gaosheng/face_detect')\n",
    "# face_recognizer = pipeline(Tasks.face_recognition, model='damo/cv_ir101_facerecognition_cfglint')\n",
    "face_recognizer = pipeline(Tasks.face_recognition, model='iic/cv_ir101_facerecognition_cfglint')\n",
    "face_bank = load_face_bank('face_bank/', face_recognizer)\n",
    "\n",
    "def inference(img: Image, draw_detect_enabled, detect_threshold, sim_threshold) -> json:\n",
    "    img = resize_img(img)\n",
    "    img = img.convert('RGB')\n",
    "    detection_result = face_detector(img)\n",
    "\n",
    "    boxes = np.array(detection_result[OutputKeys.BOXES])\n",
    "    scores = np.array(detection_result[OutputKeys.SCORES])\n",
    "    faces = []\n",
    "\n",
    "    for i in range(len(boxes)):\n",
    "        score = scores[i]\n",
    "        if score < detect_threshold:\n",
    "            continue\n",
    "        box = boxes[i]\n",
    "        face_embedding = get_face_embedding(img, box, face_recognizer)\n",
    "        name, sim = get_name_sim(face_embedding, face_bank)\n",
    "        if name is None:\n",
    "            continue\n",
    "        if sim < sim_threshold:\n",
    "            faces.append({'box': box, 'name': '未知', 'sim': sim})\n",
    "        else:\n",
    "            faces.append({'box': box, 'name': name, 'sim': sim})\n",
    "    rows = get_rows(faces)\n",
    "    row_names = get_row_names(faces, rows)\n",
    "    draw_name(img, row_names)\n",
    "    if draw_detect_enabled:\n",
    "        draw_faces(img, faces)\n",
    "    return img, get_row_names_text(row_names)\n",
    "\n",
    "examples = ['example.jpg']\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    with gr.Row():\n",
    "        draw_detect_enabled = gr.Checkbox(label=\"是否画框\", value=False)\n",
    "        detect_threshold = gr.Slider(label=\"检测阈值\", minimum=0, maximum=1, value=0.5)\n",
    "        sim_threshold = gr.Slider(label=\"识别阈值\", minimum=0, maximum=1, value=0.3)\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            img_input = gr.Image(type=\"pil\", height=350)\n",
    "            submit = gr.Button(\"提交\")\n",
    "        with gr.Column():\n",
    "            img_output = gr.Image(type=\"pil\")\n",
    "            name_output = gr.Text(label=\"人名\")\n",
    "    submit.click(\n",
    "        fn=inference, \n",
    "        inputs=[img_input, draw_detect_enabled, detect_threshold, sim_threshold],\n",
    "        outputs=[img_output, name_output])\n",
    "    gr.Examples(examples, inputs=[img_input])\n",
    "\n",
    "demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c052fc-6e66-4d7f-bc1f-e3b2084ac240",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
