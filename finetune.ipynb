{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e85739-eb52-4d84-a94c-ef2cdfb5718a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 22:03:39,825 - modelscope - INFO - PyTorch version 2.3.0+cu121 Found.\n",
      "2024-06-24 22:03:39,829 - modelscope - INFO - TensorFlow version 2.16.1 Found.\n",
      "2024-06-24 22:03:39,830 - modelscope - INFO - Loading ast index from /mnt/workspace/.cache/modelscope/ast_indexer\n",
      "2024-06-24 22:03:39,831 - modelscope - INFO - No valid ast index found from /mnt/workspace/.cache/modelscope/ast_indexer, generating ast index from prebuilt!\n",
      "2024-06-24 22:03:39,908 - modelscope - INFO - Loading done! Current index file version is 1.15.0, with md5 03830e53bae2c0a8f8ac72c969ac6ac1 and a total number of 980 components indexed\n",
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from modelscope.msdatasets import MsDataset\n",
    "from modelscope.metainfo import Trainers\n",
    "from modelscope.trainers import build_trainer\n",
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "from modelscope.utils.constant import ModelFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c2e685-76d2-415f-aad8-c7bccdf53514",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 22:03:44,527 - modelscope - INFO - No subset_name specified, defaulting to the default\n",
      "2024-06-24 22:03:45,043 - modelscope - INFO - Generating dataset wider_face_custom (/mnt/workspace/.cache/modelscope/hub/datasets/modelscope___wider_face_custom/master/train_validation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 22:03:48,027 - modelscope - WARNING - Model revision not specified, use revision: v1.1\n",
      "Downloading: 100%|██████████| 235/235 [00:00<00:00, 672B/s]\n",
      "Downloading: 100%|██████████| 5.82k/5.82k [00:00<00:00, 17.6kB/s]\n",
      "Downloading: 100%|██████████| 2.17M/2.17M [00:00<00:00, 5.78MB/s]\n",
      "Downloading: 100%|██████████| 8.10k/8.10k [00:00<00:00, 23.5kB/s]\n",
      "/usr/local/lib/python3.10/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
      "  warnings.warn(\n",
      "fatal: not a git repository (or any parent up to mount point /mnt)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "2024-06-24 22:03:55,108 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.10.14 (main, May 29 2024, 23:47:02) [GCC 11.4.0]\n",
      "CUDA available: True\n",
      "GPU 0: Tesla P100-PCIE-16GB\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 12.1, V12.1.105\n",
      "GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "PyTorch: 2.3.0+cu121\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 11.4\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.4 Product Build 20200917 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 12.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.9\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.0, CXX_COMPILER=/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=range-loop-construct -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, FORCE_FALLBACK_CUDA_MPI=1, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=OFF, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=ON, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, \n",
      "\n",
      "TorchVision: 0.18.0+cu121\n",
      "OpenCV: 4.9.0\n",
      "MMCV: 1.7.0\n",
      "MMCV Compiler: GCC 11.4\n",
      "MMCV CUDA Compiler: 12.1\n",
      "MMDetection: 2.28.2+\n",
      "------------------------------------------------------------\n",
      "\n",
      "2024-06-24 22:03:56,196 - mmdet - INFO - Distributed training: False\n",
      "2024-06-24 22:03:57,279 - mmdet - INFO - Config:\n",
      "optimizer = dict(type='SGD', lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_mult = 8\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=5000,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[440, 544])\n",
      "total_epochs = 641\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=10, hooks=[dict(type='TextLoggerHook')])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = './wider2/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt'\n",
      "workflow = [('train', 1)]\n",
      "dataset_type = 'RetinaFaceDataset'\n",
      "data_root = 'data/retinaface/'\n",
      "train_root = 'data/retinaface/train/'\n",
      "val_root = 'data/retinaface/val/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[127.5, 127.5, 127.5], std=[128.0, 128.0, 128.0], to_rgb=True)\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=1,\n",
      "    train=dict(\n",
      "        type='RetinaFaceDataset',\n",
      "        ann_file=\n",
      "        '/mnt/workspace/.cache/modelscope/hub/datasets/gaosheng/wider_face_custom/master/data_files/extracted/64c23cbe762f3bdcb2065b88c107a31be1450ddc0c2002c79d1c7e81d2bd33af/wider_train/labelv2.txt',\n",
      "        img_prefix=\n",
      "        '/mnt/workspace/.cache/modelscope/hub/datasets/gaosheng/wider_face_custom/master/data_files/extracted/64c23cbe762f3bdcb2065b88c107a31be1450ddc0c2002c79d1c7e81d2bd33af/wider_train/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile', to_float32=True),\n",
      "            dict(\n",
      "                type='LoadAnnotationsV2', with_bbox=True, with_keypoints=True),\n",
      "            dict(\n",
      "                type='RandomSquareCrop',\n",
      "                crop_choice=[1.0, 1.2, 1.4, 1.6, 1.8, 2.0]),\n",
      "            dict(type='Resize', img_scale=(640, 640), keep_ratio=False),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='PhotoMetricDistortion',\n",
      "                brightness_delta=32,\n",
      "                contrast_range=(0.5, 1.5),\n",
      "                saturation_range=(0.5, 1.5),\n",
      "                hue_delta=18),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[127.5, 127.5, 127.5],\n",
      "                std=[128.0, 128.0, 128.0],\n",
      "                to_rgb=True),\n",
      "            dict(type='DefaultFormatBundleV2'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=[\n",
      "                    'img', 'gt_bboxes', 'gt_labels', 'gt_bboxes_ignore',\n",
      "                    'gt_keypointss'\n",
      "                ])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='RetinaFaceDataset',\n",
      "        ann_file=\n",
      "        '/mnt/workspace/.cache/modelscope/hub/datasets/gaosheng/wider_face_custom/master/data_files/extracted/c04859cd918b49dc0933f829ba2c29309606f14d8627c1b67ffe3ca5ea37e9e5/wider_val/labelv2.txt',\n",
      "        img_prefix=\n",
      "        '/mnt/workspace/.cache/modelscope/hub/datasets/gaosheng/wider_face_custom/master/data_files/extracted/c04859cd918b49dc0933f829ba2c29309606f14d8627c1b67ffe3ca5ea37e9e5/wider_val/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(640, 640),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='ResizeV2', keep_ratio=True),\n",
      "                    dict(type='RandomFlipV2', flip_ratio=0.0),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[127.5, 127.5, 127.5],\n",
      "                        std=[128.0, 128.0, 128.0],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size=(640, 640), pad_val=0),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='RetinaFaceDataset',\n",
      "        ann_file='data/retinaface/val/labelv2.txt',\n",
      "        img_prefix='data/retinaface/val/images/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(640, 640),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='ResizeV2', keep_ratio=True),\n",
      "                    dict(type='RandomFlipV2', flip_ratio=0.0),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[127.5, 127.5, 127.5],\n",
      "                        std=[128.0, 128.0, 128.0],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size=(640, 640), pad_val=0),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "model = dict(\n",
      "    type='SCRFD',\n",
      "    backbone=dict(\n",
      "        type='MasterNet',\n",
      "        plainnet_struct=\n",
      "        'SuperConvK3BNRELU(3,32,2,1)SuperResIDWE1K3(32,32,2,8,1)SuperResIDWE1K7(32,64,2,40,1)SuperResIDWE1K7(64,120,2,40,2)SuperResIDWE1K5(120,160,2,120,1)'\n",
      "    ),\n",
      "    neck=dict(\n",
      "        type='PAFPN',\n",
      "        in_channels=[32, 64, 120, 160],\n",
      "        out_channels=16,\n",
      "        start_level=1,\n",
      "        add_extra_convs='on_output',\n",
      "        num_outs=3),\n",
      "    bbox_head=dict(\n",
      "        type='SCRFDHead',\n",
      "        num_classes=1,\n",
      "        in_channels=16,\n",
      "        stacked_convs=2,\n",
      "        feat_channels=64,\n",
      "        norm_cfg=dict(type='GN', num_groups=16, requires_grad=True),\n",
      "        cls_reg_share=True,\n",
      "        strides_share=True,\n",
      "        dw_conv=True,\n",
      "        scale_mode=2,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            scales=[1, 2],\n",
      "            base_sizes=[16, 64, 256],\n",
      "            strides=[8, 16, 32]),\n",
      "        loss_cls=dict(\n",
      "            type='QualityFocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            beta=2.0,\n",
      "            loss_weight=1.0),\n",
      "        loss_dfl=False,\n",
      "        reg_max=8,\n",
      "        loss_bbox=dict(type='DIoULoss', loss_weight=2.0),\n",
      "        use_kps=True,\n",
      "        loss_kps=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=0.1),\n",
      "        train_cfg=dict(\n",
      "            assigner=dict(type='ATSSAssigner', topk=9),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        test_cfg=dict(\n",
      "            nms_pre=-1,\n",
      "            min_bbox_size=0,\n",
      "            score_thr=0.02,\n",
      "            nms=dict(type='nms', iou_threshold=0.45),\n",
      "            max_per_img=-1)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(type='ATSSAssigner', topk=9),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=-1,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.02,\n",
      "        nms=dict(type='nms', iou_threshold=0.45),\n",
      "        max_per_img=-1))\n",
      "epoch_multi = 1\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "work_dir = './wider'\n",
      "device = 'cuda'\n",
      "gpu_ids = range(0, 1)\n",
      "no_validate = False\n",
      "\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:116: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "2024-06-24 22:03:57,322 - mmdet - INFO - initialize PAFPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}\n",
      "/usr/local/lib/python3.10/site-packages/mmcv/runner/base_module.py:127: UserWarning: init_weights of PAFPN has been called more than once.\n",
      "  warnings.warn(f'init_weights of {self.__class__.__name__} has '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/datasets/custom.py:181: UserWarning: CustomDataset does not support filtering empty gt images.\n",
      "  warnings.warn(\n",
      "fatal: not a git repository (or any parent up to mount point /mnt)\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/utils/compat_config.py:28: UserWarning: config is now expected to have a `runner` section, please set `runner` in your config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin image size 313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 22:03:58,918 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.\n",
      "2024-06-24 22:03:58,931 - mmdet - INFO - load checkpoint from local path: ./wider2/damo/cv_ddsar_face-detection_iclr23-damofd/pytorch_model.pt\n",
      "2024-06-24 22:03:59,032 - mmdet - INFO - the iteration number is changed due to change of GPU number\n",
      "2024-06-24 22:03:59,035 - mmdet - INFO - resumed epoch 640, iter 1031680\n",
      "2024-06-24 22:03:59,037 - mmdet - INFO - Start running, host: root@eais-bjtyd0pwdtv28jwgqq9n-98c7c6994-xdxkm, work_dir: /mnt/workspace/wider\n",
      "2024-06-24 22:03:59,038 - mmdet - INFO - Hooks will be executed in the following order:\n",
      "before_run:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_epoch:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_train_iter:\n",
      "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      " -------------------- \n",
      "after_train_iter:\n",
      "(ABOVE_NORMAL) OptimizerHook                      \n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) IterTimerHook                      \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_train_epoch:\n",
      "(NORMAL      ) CheckpointHook                     \n",
      "(LOW         ) EvalHook                           \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_epoch:\n",
      "(LOW         ) IterTimerHook                      \n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "before_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_iter:\n",
      "(LOW         ) IterTimerHook                      \n",
      " -------------------- \n",
      "after_val_epoch:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "after_run:\n",
      "(VERY_LOW    ) TextLoggerHook                     \n",
      " -------------------- \n",
      "2024-06-24 22:03:59,039 - mmdet - INFO - workflow: [('train', 1)], max: 641 epochs\n",
      "2024-06-24 22:03:59,041 - mmdet - INFO - Checkpoints will be saved to /mnt/workspace/wider by HardDiskBackend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin image size 135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /torch/pytorch/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/models/dense_heads/anchor_head.py:123: UserWarning: DeprecationWarning: anchor_generator is deprecated, please use \"prior_generator\" instead\n",
      "  warnings.warn('DeprecationWarning: anchor_generator is deprecated, '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:333: UserWarning: ``grid_anchors`` would be deprecated soon. Please use ``grid_priors`` \n",
      "  warnings.warn('``grid_anchors`` would be deprecated soon. '\n",
      "/usr/local/lib/python3.10/site-packages/mmdet/core/anchor/anchor_generator.py:369: UserWarning: ``single_level_grid_anchors`` would be deprecated soon. Please use ``single_level_grid_priors`` \n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/torch/autograd/graph.py:744: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /torch/pytorch/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "2024-06-24 22:04:05,371 - mmdet - INFO - Epoch [641][10/78]\tlr: 1.000e-04, eta: -8 days, 19:31:41, time: 0.632, data_time: 0.237, memory: 511, loss_cls: 0.1682, loss_bbox: 0.2242, loss_kps: 0.0000, loss: 0.3924\n",
      "2024-06-24 22:04:06,860 - mmdet - INFO - Epoch [641][20/78]\tlr: 1.000e-04, eta: -5 days, 13:28:09, time: 0.149, data_time: 0.018, memory: 511, loss_cls: 0.2073, loss_bbox: 0.1965, loss_kps: 0.0000, loss: 0.4038\n",
      "2024-06-24 22:04:08,380 - mmdet - INFO - Epoch [641][30/78]\tlr: 1.000e-04, eta: -4 days, 11:08:50, time: 0.152, data_time: 0.019, memory: 511, loss_cls: 0.2104, loss_bbox: 0.2058, loss_kps: 0.0000, loss: 0.4162\n",
      "2024-06-24 22:04:09,941 - mmdet - INFO - Epoch [641][40/78]\tlr: 1.000e-04, eta: -4 days, 21:42:57, time: 0.156, data_time: 0.020, memory: 511, loss_cls: 0.1633, loss_bbox: 0.2671, loss_kps: 0.0000, loss: 0.4304\n",
      "2024-06-24 22:04:11,453 - mmdet - INFO - Epoch [641][50/78]\tlr: 1.000e-04, eta: -3 days, 4:19:39, time: 0.151, data_time: 0.020, memory: 511, loss_cls: 0.1454, loss_bbox: 0.2157, loss_kps: 0.0000, loss: 0.3611\n",
      "2024-06-24 22:04:12,927 - mmdet - INFO - Epoch [641][60/78]\tlr: 1.000e-04, eta: -3 days, 8:54:18, time: 0.147, data_time: 0.019, memory: 511, loss_cls: 0.1743, loss_bbox: 0.2491, loss_kps: 0.0000, loss: 0.4234\n",
      "2024-06-24 22:04:14,388 - mmdet - INFO - Epoch [641][70/78]\tlr: 1.000e-04, eta: -3 days, 12:13:32, time: 0.146, data_time: 0.017, memory: 511, loss_cls: 0.1746, loss_bbox: 0.2409, loss_kps: 0.0000, loss: 0.4155\n",
      "2024-06-24 22:04:15,688 - mmdet - INFO - Saving checkpoint at 641 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 135/135, 33.0 task/s, elapsed: 4s, ETA:     0s\n",
      "---------------iou_thr: 0.5---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 22:04:20,236 - mmdet - INFO - \n",
      "+-------+-----+------+--------+-------+\n",
      "| class | gts | dets | recall | ap    |\n",
      "+-------+-----+------+--------+-------+\n",
      "| FG    | 162 | 8873 | 1.000  | 0.020 |\n",
      "+-------+-----+------+--------+-------+\n",
      "| mAP   |     |      |        | 0.020 |\n",
      "+-------+-----+------+--------+-------+\n",
      "2024-06-24 22:04:20,330 - mmdet - INFO - Exp name: DamoFD_0.5g_lms.py\n",
      "2024-06-24 22:04:20,331 - mmdet - INFO - Epoch(val) [641][135]\tAP50: 0.0200, mAP: 0.0199\n"
     ]
    }
   ],
   "source": [
    "model_id = 'damo/cv_ddsar_face-detection_iclr23-damofd'\n",
    "ms_ds_widerface = MsDataset.load('wider_face_custom', namespace='gaosheng')\n",
    "\n",
    "data_path = ms_ds_widerface.config_kwargs['split_config']\n",
    "train_dir = data_path['train']\n",
    "val_dir = data_path['validation']\n",
    "\n",
    "def get_name(dir_name):\n",
    "    names = [i for i in os.listdir(dir_name) if not i.startswith('_')]\n",
    "    return names[0]\n",
    "\n",
    "train_root = train_dir + '/' + get_name(train_dir) + '/'\n",
    "val_root = val_dir + '/' + get_name(val_dir) + '/'\n",
    "cache_path = snapshot_download(model_id, cache_dir = './wider2')\n",
    "tmp_dir = tempfile.TemporaryDirectory().name\n",
    "pretrain_epochs = 640\n",
    "ft_epochs = 1\n",
    "total_epochs = pretrain_epochs + ft_epochs\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.makedirs(tmp_dir)\n",
    "\n",
    "def _cfg_modify_fn(cfg):\n",
    "    cfg.checkpoint_config.interval = 1\n",
    "    cfg.log_config.interval = 10\n",
    "    cfg.evaluation.interval = 1\n",
    "    cfg.data.workers_per_gpu = 1\n",
    "    cfg.data.samples_per_gpu = 4\n",
    "    return cfg\n",
    "kwargs = dict(\n",
    "    cfg_file=os.path.join(cache_path, 'DamoFD_lms.py'),\n",
    "    save_pretrained=True,\n",
    "    work_dir=\"./wider\",\n",
    "    train_root=train_root,\n",
    "    model_dir = '.wider',\n",
    "    val_root=val_root,\n",
    "    resume_from=os.path.join(cache_path, ModelFile.TORCH_MODEL_FILE),\n",
    "    total_epochs=total_epochs,  # run #epochs\n",
    "    cfg_modify_fn=_cfg_modify_fn)\n",
    "\n",
    "trainer = build_trainer(name=Trainers.face_detection_scrfd, default_args=kwargs)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f078d9-0589-4c03-883b-f02a1ac3b7c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
